{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xpVXqCk6-vK3WdtQmrZSwCfSuatMrsbc","timestamp":1707195790463}],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyM1IfBkgZqzYxsvzjM5AE4F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install pillow\n","!pip install openai\n","!pip install --upgrade azure-cognitiveservices-vision-computervision"],"metadata":{"id":"mQ5jmx2H69l6","executionInfo":{"status":"ok","timestamp":1707134770091,"user_tz":-540,"elapsed":11273,"user":{"displayName":"Chang-Hee Ok","userId":"08332839736873339318"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bfd86a68-7c54-4ca5-b4c1-99c37527fc12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-1.11.1-py3-none-any.whl (226 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/226.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n","Collecting typing-extensions<5,>=4.7 (from openai)\n","  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.11.1 typing-extensions-4.9.0\n"]}]},{"cell_type":"code","source":["import requests\n","from PIL import Image\n","from io import BytesIO\n","from openai import OpenAI\n","from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n","from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n","from msrest.authentication import CognitiveServicesCredentials\n","import time\n","import re\n","\n","# OpenAI API Key\n","OPENAI_API_KEY = \"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\"\n","# Azure Computer Vision API Key and Endpoint\n","AZURE_SUBSCRIPTION_KEY = \"87f5a73882bc437caa277b5f952176cd\"\n","AZURE_ENDPOINT = \"https://skt-teamp-ocr.cognitiveservices.azure.com/\"\n","\n","# Function to generate image using OpenAI DALL-E\n","def generate_image(prompt):\n","    client = OpenAI(api_key=OPENAI_API_KEY)\n","    response = client.images.generate(\n","        model=\"dall-e-3\",\n","        prompt=prompt,\n","        size=\"1024x1024\",\n","        quality=\"hd\",\n","        n=1,\n","    )\n","    image_url = response.data[0].url\n","    return image_url\n","\n","# Function to perform OCR using Azure Computer Vision\n","def perform_ocr(image_data):\n","    computervision_client = ComputerVisionClient(AZURE_ENDPOINT, CognitiveServicesCredentials(AZURE_SUBSCRIPTION_KEY))\n","    read_response = computervision_client.read_in_stream(image_data, raw=True)\n","    read_operation_location = read_response.headers[\"Operation-Location\"]\n","    operation_id = read_operation_location.split(\"/\")[-1]\n","\n","    # Wait for the OCR operation to complete\n","    while True:\n","        read_result = computervision_client.get_read_result(operation_id)\n","        if read_result.status not in ['notStarted', 'running']:\n","            break\n","        time.sleep(1)\n","\n","    return read_result\n","\n","# Function to normalize text (remove punctuation and convert to lowercase)\n","def normalize_text(text):\n","    return ''.join(char.lower() for char in text if char.isalnum() or char.isspace()).strip()"],"metadata":{"id":"7F66WEJqznCw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Intended text\n","intended_text = \"blue text 'Take a delicious coffee!' on the white background, minimalism\"\n","match = re.search(r\"'(.*?)'\", intended_text)\n","intended_text_only = match.group(1)\n","\n","# Number of attempts\n","max_attempts = 30"],"metadata":{"id":"nlL3hx4xzt5X"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BPPbRQdq6wKd","executionInfo":{"status":"ok","timestamp":1707135304274,"user_tz":-540,"elapsed":100227,"user":{"displayName":"Chang-Hee Ok","userId":"08332839736873339318"}},"outputId":"0b4e96fa-1cd2-4ded-bfa3-2b2ef32c6ea1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Attempt 1:\n","OCR Result: brea s  take  delicous coffee coffee\n","OCR result does not match intended text. Regenerating image...\n","\n","Attempt 2:\n","OCR Result: take delicious coffee\n","OCR result does not match intended text. Regenerating image...\n","\n","Attempt 3:\n","OCR Result: take delicious coffee\n","OCR result does not match intended text. Regenerating image...\n","\n","Attempt 4:\n","OCR Result: a lea deli cious 2 coffee\n","OCR result does not match intended text. Regenerating image...\n","\n","Attempt 5:\n","OCR Result: take a delicious coffee\n","OCR result matches intended text:\n","- TAKE A Delicious Coffee! \n"]}],"source":["# Loop until OCR result matches intended text or reach max_attempts\n","for attempt in range(1, max_attempts + 1):\n","    print(f\"\\nAttempt {attempt}:\")\n","\n","    # Generate image using OpenAI DALL-E\n","    img_url = generate_image(intended_text)\n","\n","    # Download the image\n","    response = requests.get(img_url)\n","    if response.status_code == 200:\n","        # Open the image using PIL\n","        img = Image.open(BytesIO(response.content))\n","\n","        # Save the image in PNG format\n","        img.save(\"./image.png\", format=\"PNG\")\n","\n","        # Perform OCR on the image\n","        with open(\"./image.png\", \"rb\") as image_file:\n","            image_data = image_file.read()\n","        image_data_io = BytesIO(image_data)\n","        ocr_result = perform_ocr(image_data_io)\n","\n","        # Extract text from OCR result and normalize\n","        extracted_text = \"\"\n","        if ocr_result.status == OperationStatusCodes.succeeded:\n","            for text_result in ocr_result.analyze_result.read_results:\n","                for line in text_result.lines:\n","                    extracted_text += line.text + \" \"\n","\n","        extracted_text_normalized = normalize_text(extracted_text)\n","        intended_text_normalized = normalize_text(intended_text_only)\n","\n","        # Print the OCR result for each attempt\n","        print(f\"OCR Result: {extracted_text_normalized}\")\n","\n","        # Check if the normalized extracted text matches the normalized intended text\n","        if extracted_text_normalized == intended_text_normalized:\n","            print(\"OCR result matches intended text:\")\n","            print(extracted_text)\n","            break\n","        else:\n","            print(\"OCR result does not match intended text. Regenerating image...\")\n","    else:\n","        print(\"Failed to download the image. Status code:\", response.status_code)"]},{"cell_type":"code","source":[],"metadata":{"id":"-ddFrr9CLRqg"},"execution_count":null,"outputs":[]}]}